{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Every-visit Monte Carlo with Exploring Starts for estimating an optimal Blackjack policy\n",
    "\n",
    "This corresponds to the algorithm described in Chapter 5.3 of [_Reinforcement Learning: An Introduction_](http://incompleteideas.net/book/the-book-2nd.html), by Sutton and Barto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rl_agents.blackjack.MonteCarloAgent import MonteCarloAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Blackjack agent and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2\n",
    "\n",
    "env = gym.make('Blackjack-v0')\n",
    "env.seed(seed=RANDOM_SEED)\n",
    "agent = MonteCarloAgent(action_space=env.action_space,\n",
    "                        obs_space=env.observation_space,\n",
    "                        seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:08<00:00, 11829.09it/s]\n"
     ]
    }
   ],
   "source": [
    "NUM_EPISODES = 100000\n",
    "\n",
    "for i_episode in tqdm(range(NUM_EPISODES)):\n",
    "    observation = env.reset()\n",
    "    reward = 0\n",
    "    done = False\n",
    "    t = 0\n",
    "    episode_ts = []\n",
    "    while not done:\n",
    "        action = agent.agent_step(reward=reward,\n",
    "                                  observation=observation)\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        episode_ts.append((action, observation, reward))\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    agent.agent_end(episode_ts=episode_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the agent\n",
    "with open(\"/home/protoman/dev/rl_agents/rl_agents/blackjack/agents/{}_mc_episodes={}.pkl\".format(int(time.time()), NUM_EPISODES), \"wb\") as fp:\n",
    "    pickle.dump(agent, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze agent's policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_labels = [\"A\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
    "x_title = \"Dealer showing\"\n",
    "y_labels = [\"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\"]\n",
    "y_title = \"Player Sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06185567 -0.03333333]\n",
      "(32, 11, 2)\n"
     ]
    }
   ],
   "source": [
    "print(agent.action_values[18][3][0])\n",
    "print(agent.policy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(agent.action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has Usable Ace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Usable Ace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_agents",
   "language": "python",
   "name": "rl_agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
